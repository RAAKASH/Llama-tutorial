# Llama tutorial
 Sample codes to run Run Quantized LLM models on your CPU
